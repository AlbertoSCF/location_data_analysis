{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7989f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2, os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98abe7ea",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Collecting and processing the data\n",
    "\n",
    "The data is downloaded as zip files from [Meta's data for good](https://dataforgood.facebook.com/dfg/tools/high-resolution-population-density-maps) platform. Once downloaded, the data is decompressed into the source csv files.\n",
    "\n",
    "Now we process these files to give them a common format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c807d30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>population</th>\n",
       "      <th>date</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-13.999861</td>\n",
       "      <td>-50.926250</td>\n",
       "      <td>0.773618</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>population_bra_northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.999861</td>\n",
       "      <td>-50.832361</td>\n",
       "      <td>0.687046</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>population_bra_northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.999861</td>\n",
       "      <td>-49.926806</td>\n",
       "      <td>1.193779</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>population_bra_northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.999861</td>\n",
       "      <td>-49.863472</td>\n",
       "      <td>1.001150</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>population_bra_northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-13.999861</td>\n",
       "      <td>-49.764583</td>\n",
       "      <td>0.842562</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>population_bra_northeast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude  longitude  population        date                   segment\n",
       "0 -13.999861 -50.926250    0.773618  2018-10-01  population_bra_northeast\n",
       "1 -13.999861 -50.832361    0.687046  2018-10-01  population_bra_northeast\n",
       "2 -13.999861 -49.926806    1.193779  2018-10-01  population_bra_northeast\n",
       "3 -13.999861 -49.863472    1.001150  2018-10-01  population_bra_northeast\n",
       "4 -13.999861 -49.764583    0.842562  2018-10-01  population_bra_northeast"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each file\n",
    "i=0\n",
    "for file in tqdm(os.listdir(\"data/population_density/csv/\")):\n",
    "    if file!='.DS_Store':\n",
    "        \n",
    "        # Read the data and pars its params\n",
    "        data = pd.read_csv(f\"data/population_density/csv/{file}\")\n",
    "        date = file.split('-')[0][-4:]+'-'+file.split('-')[1]+'-'+file.split('-')[2][:2]\n",
    "        segment = file.split('-')[0][:-5]\n",
    "        \n",
    "        # Add info\n",
    "        data['date'] = date\n",
    "        data['segment'] = segment\n",
    "        \n",
    "        # To S3\n",
    "        if 'population_2020' in data.columns:\n",
    "            data = data.rename(columns={'population_2020': 'population'})\n",
    "        data[['latitude', \n",
    "              'longitude', \n",
    "              'population', \n",
    "              'date', \n",
    "              'segment']].to_csv(f'data/population_density/to_s3/file_{i}.csv', index=False)\n",
    "        i+=1\n",
    "        \n",
    "# Check some of the data created\n",
    "pd.read_csv(f\"data/population_density/population_density/file_0.csv\").head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1c0469",
   "metadata": {},
   "source": [
    "Data is uploaded to `s3://postgres-staging-data/population_density/`\n",
    "\n",
    "---\n",
    "## 2.  Data to postgres\n",
    "\n",
    "Establish connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe87bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection and create its cursor\n",
    "try: \n",
    "    conn = psycopg2.connect(f\"host={os.environ['AURORA_POSTGRES_HOST']} dbname={os.environ['AURORA_POSTGRES_DATABASE']} user={os.environ['AURORA_POSTGRES_USERNAME']} password={os.environ['AURORA_POSTGRES_PWD']}\")\n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Could not make connection to the Postgres database\")\n",
    "    print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b19e72",
   "metadata": {},
   "source": [
    "Create table to store this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table\n",
    "cur.execute(\"CREATE TABLE staging_tables.population_density (latitude numeric, longitude numeric, population bigint, date varchar, segment varchar)\")\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34b5c33",
   "metadata": {},
   "source": [
    "Load the data from S3 to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5dd4bb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AWS_ACCESS_KEY_ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/32/vpy2r3p94d9fyxp930tz7p700000gn/T/ipykernel_3337/2152605734.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             ),\n\u001b[1;32m     12\u001b[0m         aws_commons.create_aws_credentials(\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;34m'{os.environ['\u001b[0m\u001b[0mAWS_ACCESS_KEY_ID\u001b[0m\u001b[0;34m']}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;34m'{os.environ['\u001b[0m\u001b[0mAWS_SECRET_ACCESS_KEY\u001b[0m\u001b[0;34m']}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;34m'{os.environ['\u001b[0m\u001b[0mAWS_SESSION_TOKEN\u001b[0m\u001b[0;34m']}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/default_env/lib/python3.9/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AWS_ACCESS_KEY_ID'"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    statement = f\"\"\"\n",
    "        SELECT aws_s3.table_import_from_s3(\n",
    "        'staging_tables.population_density',\n",
    "        'latitude,longitude,population,date, segment',\n",
    "        '(FORMAT CSV, HEADER true)',\n",
    "        aws_commons.create_s3_uri(\n",
    "            'postgres-staging-data',\n",
    "            'population_density/2021-12/file_{i}.csv',\n",
    "            'global'\n",
    "            ),\n",
    "        aws_commons.create_aws_credentials(\n",
    "            '{os.environ['AWS_ACCESS_KEY_ID']}',\n",
    "            '{os.environ['AWS_SECRET_ACCESS_KEY']}'\n",
    "            )\n",
    "        );\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
